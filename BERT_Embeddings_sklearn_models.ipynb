{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10126,
     "status": "ok",
     "timestamp": 1588530350146,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "7rWryW65eV5Y",
    "outputId": "26b8345c-8d57-47e9-c437-96640f87ee65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\u001b[K     |████████████████████████████████| 573kB 4.8MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 58.3MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 42.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 46.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=c1446cf307f8e4a97a6a80e6906ad9db548c54188ae2c2194df0805068e99d75\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.12.47)\n",
      "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.15.47)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDyJR1DyiOvy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    XLNetConfig, \n",
    "    XLNetForSequenceClassification, \n",
    "    XLNetTokenizer,\n",
    "    XLMConfig, \n",
    "    XLMForSequenceClassification, \n",
    "    XLMTokenizer,\n",
    "    RobertaConfig, \n",
    "    RobertaForSequenceClassification, \n",
    "    RobertaTokenizer,\n",
    "    DistilBertConfig, \n",
    "    DistilBertForSequenceClassification, \n",
    "    DistilBertTokenizer,\n",
    "    AlbertConfig, \n",
    "    AlbertForSequenceClassification, \n",
    "    AlbertTokenizer,\n",
    "    XLMRobertaConfig, \n",
    "    XLMRobertaForSequenceClassification, \n",
    "    XLMRobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I82-yQFQJeTr"
   },
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    \"xlnet\": (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    \"xlm\": (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),\n",
    "    \"distilbert\": (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer),\n",
    "    \"albert\": (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer),\n",
    "    \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer),\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "cd614c290f664956af913d5298a5190b",
      "8e8e02dffa8f41369d617d3da863424a",
      "d41831db0c2c4bc5a9acf00890aee606",
      "accaed8276224bf487b93e6b15f40d6e",
      "30d661484aea40e79834a5a481cfa46e",
      "c4c0e49a514145a589582a3f166983a7",
      "f1889c9742074bff969e5807491ce2c8",
      "d735dea685f3455881a98c9e37184bf7",
      "bc2a4bbdfbe64cd2b46fd1f01630ea9c",
      "90a7d3835aa04a048a97bda55dbabd82",
      "c43685ccbbf6494dba503c20736fd8f3",
      "f4ace6074c4d4dbe86f5315a940c701a",
      "2e1b67a858004ebe91cdd1125393fd80",
      "4e0b92ca9ea24941a58e074d3f5c1587",
      "7b35473d2f2d4a27b890a1ddc33e4b3b",
      "453b3dd2b520496daae938cf375f2bc6",
      "90a56fc73fdc4b8babeed87f51c2d276",
      "6e1252bdb09c44c38ae60a79950e75b3",
      "508d6e6c03804db7b052ec4c242bc165",
      "848fb7c01d414e94969602871542ceeb",
      "45d954be1e4d49929e5c49339cd31e49",
      "424e984d8a354928a2cfd0c44a3dfc6a",
      "4ac31b9ee30543d2abba31109b22a9b4",
      "43b5ab7195994637b9870a585ea019f0"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31073,
     "status": "ok",
     "timestamp": 1588530371116,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "jLatveM7J1o5",
    "outputId": "38b88657-58b3-4dac-d4cd-7d0043018e8d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd614c290f664956af913d5298a5190b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2a4bbdfbe64cd2b46fd1f01630ea9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=435779157, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a56fc73fdc4b8babeed87f51c2d276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Model setup\n",
    "model_type = 'bert'\n",
    "model_name = 'bert-base-cased'\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "\n",
    "config = config_class.from_pretrained(model_name, num_labels=50, output_hidden_states=True)\n",
    "model = model_class.from_pretrained(model_name, config=config)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name, do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pN-sWy7XUVe3"
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "MAX_LEN = 128\n",
    "batch_size = 32\n",
    "lr = 4e-5\n",
    "eps = 1e-8\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99uCftDRiOwB"
   },
   "outputs": [],
   "source": [
    "ROOT = \"\"\n",
    "DATA_PATH = ROOT + 'datasets/'\n",
    "def get_data(subset='train'):\n",
    "    texts = []\n",
    "    for root, folders, files in os.walk(DATA_PATH + '/C50/C50{}'.format(subset)):\n",
    "        if len(files) == 0:\n",
    "            continue\n",
    "\n",
    "        author = root.split('/')[-1]\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    texts.append({\n",
    "                        'author': author,\n",
    "                        'text': f.read(),\n",
    "\n",
    "                    })\n",
    "    df = pd.DataFrame(texts)\n",
    "    unique_authors = sorted(df['author'].unique())\n",
    "    num_authors = len(unique_authors)\n",
    "    author_to_id = { unique_authors[i]: i for i in range(num_authors) }\n",
    "    df = df.assign(author_id=df['author'].apply(lambda a: author_to_id[a]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLNmwPLyiOwE"
   },
   "outputs": [],
   "source": [
    "def get_encodings(texts):\n",
    "    token_ids = []\n",
    "    attention_masks = []\n",
    "    for text in texts:\n",
    "        token_id = tokenizer.encode(text, \n",
    "                                    add_special_tokens=True, \n",
    "                                    max_length=MAX_LEN,\n",
    "                                    pad_to_max_length=True)\n",
    "        token_ids.append(token_id)\n",
    "    return token_ids\n",
    "\n",
    "\n",
    "\n",
    "def get_attention_masks(padded_encodings):\n",
    "    attention_masks = []\n",
    "    for encoding in padded_encodings:\n",
    "        attention_mask = [int(token_id > 0) for token_id in encoding]\n",
    "        attention_masks.append(attention_mask)\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qz4sWj33nTz"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(DATA_PATH + 'reuters50_train.pkl')\n",
    "test_df = pd.read_pickle(DATA_PATH + 'reuters50_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWjVYsuPvaVW"
   },
   "outputs": [],
   "source": [
    "train_encodings = get_encodings(train_df.text.values)\n",
    "train_attention_masks = get_attention_masks(train_encodings)\n",
    "\n",
    "test_encodings = get_encodings(test_df.text.values)\n",
    "test_attention_masks = get_attention_masks(test_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BfjMuKciOwK"
   },
   "outputs": [],
   "source": [
    "train_input_ids = torch.tensor(train_encodings)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "train_labels = torch.tensor(train_df.author_id.values)\n",
    "\n",
    "\n",
    "test_input_ids = torch.tensor(test_encodings)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_labels = torch.tensor(test_df.author_id.values)\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_input_ids, train_masks, train_labels)\n",
    "train_sampler = SequentialSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(test_input_ids, test_masks, test_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 92684,
     "status": "ok",
     "timestamp": 1588530432784,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "cKetuFLPiOwN",
    "outputId": "a299ae24-baa8-4434-8b9b-e2dc6711ca25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCk5nwZyiOwR"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def get_confusion_matrix(preds, labels):\n",
    "    \"\"\"\n",
    "    Rows = true labels\n",
    "    Columns = classified labels\n",
    "    \"\"\"\n",
    "    confusion_matrix = np.zeros((50, 50))\n",
    "    preds = np.argmax(preds, axis=1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    for i, label in enumerate(labels):\n",
    "        pred = preds[i]\n",
    "        confusion_matrix[label][pred] += 1\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "def parse_confusion_matrix(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Rows = labels\n",
    "    Col0 = tp\n",
    "    Col1 = fp\n",
    "    Col2 = fn\n",
    "    Col3 = tn\n",
    "    \"\"\"\n",
    "    parsed_confusion_matrix = np.zeros((50, 4))\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        tp = confusion_matrix[i][i]\n",
    "        fp = confusion_matrix[:, i].sum() - tp\n",
    "        fn = confusion_matrix[i, :].sum() - tp \n",
    "        tn = confusion_matrix.sum() - tp - fp - fn\n",
    "        # print(f'Label: {i}, tp: {tp}, fp: {fp}, fn: {fn}, tn: {tn}')\n",
    "        parsed_confusion_matrix[i][0] = tp\n",
    "        parsed_confusion_matrix[i][1] = fp\n",
    "        parsed_confusion_matrix[i][2] = fn\n",
    "        parsed_confusion_matrix[i][3] = tn\n",
    "    return parsed_confusion_matrix\n",
    "\n",
    "def calculate_avg_precision(parsed_confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates macro average precision\n",
    "    \"\"\"\n",
    "    total_precision = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, fp, _, _ = parsed_confusion_matrix[i]\n",
    "        precision = tp / (tp + fp)\n",
    "        if not np.isnan(precision):\n",
    "            total_precision += precision\n",
    "    return total_precision / num_classes\n",
    "\n",
    "def calculate_avg_recall(parsed_confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates macro average recall\n",
    "    \"\"\"\n",
    "    total_recall = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, _, fn, _ = parsed_confusion_matrix[i]\n",
    "        recall = tp / (tp + fn)\n",
    "        if not np.isnan(recall):\n",
    "            total_recall += recall\n",
    "    return total_recall / num_classes\n",
    "\n",
    "def calculate_avg_f1(parsed_confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates macro average f1 score\n",
    "    \"\"\"\n",
    "    total_f1 = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, fp, fn, _ = parsed_confusion_matrix[i]\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2*((precision * recall) / (precision + recall))\n",
    "        if not np.isnan(f1):\n",
    "            total_f1 += f1\n",
    "    return total_f1 / num_classes\n",
    "\n",
    "def calculate_avg_mcc(parsed_confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates macro average Matthews correlation coefficient\n",
    "    \"\"\"\n",
    "    total_mcc = 0\n",
    "    num_classes = parsed_confusion_matrix.shape[0]\n",
    "    for i in range(num_classes):\n",
    "        tp, fp, fn, tn = parsed_confusion_matrix[i]\n",
    "        mcc = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "        if not np.isnan(mcc):\n",
    "            total_mcc += mcc\n",
    "    return total_mcc / num_classes\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ReZQjKdn8e-"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#         Get Training Embeddings\n",
    "# ========================================\n",
    "\n",
    "model.eval()\n",
    "train_features = None\n",
    "for batch in train_dataloader:\n",
    "\n",
    "    b_texts = batch[0].to(device)\n",
    "    b_attention_masks = batch[1].to(device)\n",
    "    b_authors = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_texts, \n",
    "                        attention_mask=b_attention_masks, \n",
    "                        labels=b_authors)\n",
    "    \n",
    "    loss = outputs[0]\n",
    "    logits = outputs[1]\n",
    "    hidden_states = outputs[2][0]\n",
    "\n",
    "    if train_features is None:\n",
    "        train_features = hidden_states\n",
    "    else:\n",
    "        train_features = torch.cat((train_features, hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1JjmFssiOwV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ========================================\n",
    "#         Get Validation Embeddings\n",
    "# ========================================\n",
    "\n",
    "\n",
    "model.eval()\n",
    "test_features = None\n",
    "\n",
    "for batch in validation_dataloader:\n",
    "    \n",
    "    b_texts = batch[0].to(device)\n",
    "    b_attention_masks = batch[1].to(device)\n",
    "    b_authors = batch[2].to(device)\n",
    "   \n",
    "    with torch.no_grad():        \n",
    "\n",
    "        outputs = model(b_texts, \n",
    "                        attention_mask=b_attention_masks,\n",
    "                        labels=b_authors\n",
    "                        )\n",
    "\n",
    "    loss = outputs[0]\n",
    "    logits = outputs[1]\n",
    "    hidden_states = outputs[2][0]\n",
    "\n",
    "    if test_features is None:\n",
    "        test_features = hidden_states\n",
    "    else:\n",
    "        test_features = torch.cat((test_features, hidden_states))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJkaBYUAgtoi"
   },
   "outputs": [],
   "source": [
    "train_features = train_features.mean(dim=1).double().to(device)\n",
    "test_features = test_features.mean(dim=1).double().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELfe10TFLAFD"
   },
   "source": [
    "Import BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114974,
     "status": "ok",
     "timestamp": 1588530455124,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "XTe8rxGqK64K",
    "outputId": "5bf6f2dd-4846-4c9a-861f-77d6336358f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/Shared drives/CIS530_Project/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "bow_train = pickle.load(open(DATA_PATH +'text_bow_train.p', 'rb'))\n",
    "bow_test = pickle.load(open(DATA_PATH +'text_bow_test.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvxD7zI5jpII"
   },
   "outputs": [],
   "source": [
    "bow_train_t = torch.tensor(bow_train.todense(), dtype=torch.float64).to(device)\n",
    "bow_test_t = torch.tensor(bow_test.todense(), dtype=torch.float64).to(device)\n",
    "\n",
    "# bow_train_t\n",
    "train_features = torch.cat((train_features, bow_train_t), dim=1)\n",
    "test_features = torch.cat((test_features, bow_test_t), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXEqWj3B7e0D"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 341045,
     "status": "ok",
     "timestamp": 1588530681226,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "y1unqkeYH_Rw",
    "outputId": "35747b6b-5115-4bc1-c46a-f6e60c7afd60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "rdf = RandomForestClassifier(n_estimators = 1000)\n",
    "rdf.fit(train_features.cpu(), train_labels.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icE1et09I9Nc"
   },
   "outputs": [],
   "source": [
    "predictions = rdf.predict(test_features.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 973,
     "status": "ok",
     "timestamp": 1588460430964,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "fDW0WNPuKwQJ",
    "outputId": "f50c3dcc-b848-4a6f-dd95-59ad668aee11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78        10\n",
      "           1       0.58      0.70      0.64        10\n",
      "           2       0.57      0.40      0.47        10\n",
      "           3       0.83      0.50      0.62        10\n",
      "           4       1.00      0.70      0.82        10\n",
      "           5       0.67      0.40      0.50        10\n",
      "           6       1.00      0.50      0.67        10\n",
      "           7       0.62      0.50      0.56        10\n",
      "           8       0.78      0.70      0.74        10\n",
      "           9       1.00      0.20      0.33        10\n",
      "          10       0.90      0.90      0.90        10\n",
      "          11       0.60      0.90      0.72        10\n",
      "          12       0.78      0.70      0.74        10\n",
      "          13       0.60      0.60      0.60        10\n",
      "          14       0.70      0.70      0.70        10\n",
      "          15       0.71      1.00      0.83        10\n",
      "          16       0.78      0.70      0.74        10\n",
      "          17       0.50      0.70      0.58        10\n",
      "          18       0.83      0.50      0.62        10\n",
      "          19       0.55      0.60      0.57        10\n",
      "          20       0.53      1.00      0.69        10\n",
      "          21       0.75      0.90      0.82        10\n",
      "          22       0.67      0.80      0.73        10\n",
      "          23       0.40      0.20      0.27        10\n",
      "          24       0.80      0.40      0.53        10\n",
      "          25       0.77      1.00      0.87        10\n",
      "          26       1.00      0.70      0.82        10\n",
      "          27       0.80      0.80      0.80        10\n",
      "          28       0.75      0.90      0.82        10\n",
      "          29       0.82      0.90      0.86        10\n",
      "          30       0.46      0.60      0.52        10\n",
      "          31       0.45      0.50      0.48        10\n",
      "          32       1.00      0.70      0.82        10\n",
      "          33       0.70      0.70      0.70        10\n",
      "          34       0.50      0.40      0.44        10\n",
      "          35       0.50      0.50      0.50        10\n",
      "          36       0.82      0.90      0.86        10\n",
      "          37       0.45      1.00      0.62        10\n",
      "          38       1.00      0.50      0.67        10\n",
      "          39       0.73      0.80      0.76        10\n",
      "          40       1.00      1.00      1.00        10\n",
      "          41       0.54      0.70      0.61        10\n",
      "          42       0.59      1.00      0.74        10\n",
      "          43       0.25      0.10      0.14        10\n",
      "          44       0.64      0.70      0.67        10\n",
      "          45       0.67      0.40      0.50        10\n",
      "          46       0.86      0.60      0.71        10\n",
      "          47       0.44      0.40      0.42        10\n",
      "          48       0.64      0.70      0.67        10\n",
      "          49       0.53      0.80      0.64        10\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.69      0.67      0.66       500\n",
      "weighted avg       0.69      0.67      0.66       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels.cpu(),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1588533278451,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "2ntFgCdf7X4Y",
    "outputId": "4f4abbf6-7207-4dc4-b4a1-5175643dfdf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Actual x Prediction Confusion Matrix')"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "confusion = metrics.confusion_matrix(test_labels.cpu(), predictions)\n",
    "sns.heatmap(confusion).set_title(\"Actual x Prediction Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1588535103348,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "G0ROCWEvEUfQ",
    "outputId": "14560dad-d37b-4646-fc16-808ddd1d0a64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21,\n",
       "        21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23,\n",
       "        23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
       "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "        28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30,\n",
       "        30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32,\n",
       "        32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41,\n",
       "        41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43,\n",
       "        43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "        45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46,\n",
       "        46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48,\n",
       "        48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49])"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df\n",
    "test_labels = torch.tensor(test_df.author_id.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYfzaSRp7bEc"
   },
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nr4a_92uoDeF"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MP2OTnyYoUt1"
   },
   "outputs": [],
   "source": [
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "    \n",
    "}\n",
    "classifier=xgboost.XGBClassifier()\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,n_jobs=-1,verbose=3)\n",
    "# random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1387020,
     "status": "error",
     "timestamp": 1588532682736,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "DMe-rN3eo0as",
    "outputId": "76c1eedf-3747-4d2b-a729-077f840d7627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-295efdbfdb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_search.fit(train_features.cpu().numpy(),train_labels.numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1588461691832,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "soSaEaBSq2Ps",
    "outputId": "d2fde82b-5386-446c-cadb-b63ee6ecb735"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, gamma=0.1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNFyzL0Sq4Zj"
   },
   "outputs": [],
   "source": [
    "classifier=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.4, gamma=0.1,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nA-24tExs1Q_"
   },
   "outputs": [],
   "source": [
    "classifier.fit(train_features.cpu(), train_labels.cpu())\n",
    "predictions = classifier.predict(test_features.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1588462467078,
     "user": {
      "displayName": "Tina Huang",
      "photoUrl": "",
      "userId": "12678607099865179429"
     },
     "user_tz": 240
    },
    "id": "uMKpZQxCs9fa",
    "outputId": "cdaca8cf-96e3-4090-e56a-cea515ea1406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55        10\n",
      "           1       0.56      0.50      0.53        10\n",
      "           2       0.57      0.80      0.67        10\n",
      "           3       0.46      0.60      0.52        10\n",
      "           4       0.78      0.70      0.74        10\n",
      "           5       0.45      0.50      0.48        10\n",
      "           6       0.80      0.40      0.53        10\n",
      "           7       0.71      0.50      0.59        10\n",
      "           8       0.75      0.90      0.82        10\n",
      "           9       0.78      0.70      0.74        10\n",
      "          10       0.78      0.70      0.74        10\n",
      "          11       0.67      0.80      0.73        10\n",
      "          12       0.62      0.80      0.70        10\n",
      "          13       0.67      0.80      0.73        10\n",
      "          14       0.46      0.60      0.52        10\n",
      "          15       0.75      0.90      0.82        10\n",
      "          16       0.70      0.70      0.70        10\n",
      "          17       0.89      0.80      0.84        10\n",
      "          18       1.00      0.80      0.89        10\n",
      "          19       1.00      0.70      0.82        10\n",
      "          20       0.77      1.00      0.87        10\n",
      "          21       0.83      1.00      0.91        10\n",
      "          22       0.67      0.60      0.63        10\n",
      "          23       0.43      0.30      0.35        10\n",
      "          24       0.67      0.60      0.63        10\n",
      "          25       0.82      0.90      0.86        10\n",
      "          26       1.00      0.70      0.82        10\n",
      "          27       0.80      0.80      0.80        10\n",
      "          28       1.00      0.80      0.89        10\n",
      "          29       0.89      0.80      0.84        10\n",
      "          30       1.00      0.80      0.89        10\n",
      "          31       0.29      0.20      0.24        10\n",
      "          32       0.89      0.80      0.84        10\n",
      "          33       0.78      0.70      0.74        10\n",
      "          34       0.67      0.40      0.50        10\n",
      "          35       0.38      0.30      0.33        10\n",
      "          36       0.53      0.80      0.64        10\n",
      "          37       0.62      0.80      0.70        10\n",
      "          38       0.45      0.50      0.48        10\n",
      "          39       0.88      0.70      0.78        10\n",
      "          40       0.91      1.00      0.95        10\n",
      "          41       0.64      0.70      0.67        10\n",
      "          42       0.69      0.90      0.78        10\n",
      "          43       1.00      0.40      0.57        10\n",
      "          44       0.70      0.70      0.70        10\n",
      "          45       0.56      0.50      0.53        10\n",
      "          46       0.75      0.90      0.82        10\n",
      "          47       0.64      0.70      0.67        10\n",
      "          48       0.45      0.50      0.48        10\n",
      "          49       0.62      0.80      0.70        10\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.70      0.69      0.68       500\n",
      "weighted avg       0.70      0.69      0.68       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels.cpu(),predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_Embeddings_sklearn_models.ipynb",
   "provenance": [
    {
     "file_id": "1A-aymWkrJ4mcOs2F_rQuyvG0t-yBhl8O",
     "timestamp": 1588451375394
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2e1b67a858004ebe91cdd1125393fd80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "30d661484aea40e79834a5a481cfa46e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "424e984d8a354928a2cfd0c44a3dfc6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43b5ab7195994637b9870a585ea019f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "453b3dd2b520496daae938cf375f2bc6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45d954be1e4d49929e5c49339cd31e49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4ac31b9ee30543d2abba31109b22a9b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e0b92ca9ea24941a58e074d3f5c1587": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "508d6e6c03804db7b052ec4c242bc165": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_424e984d8a354928a2cfd0c44a3dfc6a",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45d954be1e4d49929e5c49339cd31e49",
      "value": 213450
     }
    },
    "6e1252bdb09c44c38ae60a79950e75b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b35473d2f2d4a27b890a1ddc33e4b3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "848fb7c01d414e94969602871542ceeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43b5ab7195994637b9870a585ea019f0",
      "placeholder": "​",
      "style": "IPY_MODEL_4ac31b9ee30543d2abba31109b22a9b4",
      "value": " 213k/213k [00:00&lt;00:00, 873kB/s]"
     }
    },
    "8e8e02dffa8f41369d617d3da863424a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90a56fc73fdc4b8babeed87f51c2d276": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_508d6e6c03804db7b052ec4c242bc165",
       "IPY_MODEL_848fb7c01d414e94969602871542ceeb"
      ],
      "layout": "IPY_MODEL_6e1252bdb09c44c38ae60a79950e75b3"
     }
    },
    "90a7d3835aa04a048a97bda55dbabd82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "accaed8276224bf487b93e6b15f40d6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d735dea685f3455881a98c9e37184bf7",
      "placeholder": "​",
      "style": "IPY_MODEL_f1889c9742074bff969e5807491ce2c8",
      "value": " 433/433 [00:00&lt;00:00, 647B/s]"
     }
    },
    "bc2a4bbdfbe64cd2b46fd1f01630ea9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c43685ccbbf6494dba503c20736fd8f3",
       "IPY_MODEL_f4ace6074c4d4dbe86f5315a940c701a"
      ],
      "layout": "IPY_MODEL_90a7d3835aa04a048a97bda55dbabd82"
     }
    },
    "c43685ccbbf6494dba503c20736fd8f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e0b92ca9ea24941a58e074d3f5c1587",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e1b67a858004ebe91cdd1125393fd80",
      "value": 435779157
     }
    },
    "c4c0e49a514145a589582a3f166983a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd614c290f664956af913d5298a5190b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d41831db0c2c4bc5a9acf00890aee606",
       "IPY_MODEL_accaed8276224bf487b93e6b15f40d6e"
      ],
      "layout": "IPY_MODEL_8e8e02dffa8f41369d617d3da863424a"
     }
    },
    "d41831db0c2c4bc5a9acf00890aee606": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4c0e49a514145a589582a3f166983a7",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30d661484aea40e79834a5a481cfa46e",
      "value": 433
     }
    },
    "d735dea685f3455881a98c9e37184bf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1889c9742074bff969e5807491ce2c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4ace6074c4d4dbe86f5315a940c701a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_453b3dd2b520496daae938cf375f2bc6",
      "placeholder": "​",
      "style": "IPY_MODEL_7b35473d2f2d4a27b890a1ddc33e4b3b",
      "value": " 436M/436M [00:13&lt;00:00, 32.1MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
